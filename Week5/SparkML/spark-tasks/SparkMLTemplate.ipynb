{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "#set seed\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PySparkML\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.206:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkML</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f56856d8040>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №1 Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные для применения линейной регрессии <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week5/SparkML/spark-tasks/linear_regression.parquet\">linear_regression.parquet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df = spark.read.parquet(\"./linear_regression.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте учителя линейной регресии со следующими параметрами:\n",
    "maxIter=20\n",
    "regParam=0.5\n",
    "elasticNetParam=0.75<br>\n",
    "<a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression\">LinearRegression</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol = 'features', labelCol = 'label', maxIter = 20, regParam = 0.5, elasticNetParam = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните обучения на загруженных данных и сохраните результат в переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(dataset = lr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите следующие параметры полученной модели rootMeanSquaredError (RMSE), r2 и округлити их до 3его знака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01740889330766371"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol = 'label', predictionCol = 'prediction', metricName = \"r2\")\n",
    "evaluator.evaluate(lrModel.transform(lr_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №2 Кластеризация (K-Means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные для применения из <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week5/SparkML/spark-tasks/wine.parquet\">wine.parquet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = spark.read.parquet(\"./wine.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----+------------+---------+-------------+----------+--------------------+---------------+---------------+----+-----+-------+----------------+\n",
      "|Alcohol|Malic_Acid| Ash|Ash_Alcanity|Magnesium|Total_Phenols|Flavanoids|Nonflavanoid_Phenols|Proanthocyanins|Color_Intensity| Hue|OD280|Proline|Customer_Segment|\n",
      "+-------+----------+----+------------+---------+-------------+----------+--------------------+---------------+---------------+----+-----+-------+----------------+\n",
      "|  14.23|      1.71|2.43|        15.6|      127|          2.8|      3.06|                0.28|           2.29|           5.64|1.04| 3.92|   1065|               1|\n",
      "|   13.2|      1.78|2.14|        11.2|      100|         2.65|      2.76|                0.26|           1.28|           4.38|1.05|  3.4|   1050|               1|\n",
      "|  13.16|      2.36|2.67|        18.6|      101|          2.8|      3.24|                 0.3|           2.81|           5.68|1.03| 3.17|   1185|               1|\n",
      "|  14.37|      1.95| 2.5|        16.8|      113|         3.85|      3.49|                0.24|           2.18|            7.8|0.86| 3.45|   1480|               1|\n",
      "|  13.24|      2.59|2.87|        21.0|      118|          2.8|      2.69|                0.39|           1.82|           4.32|1.04| 2.93|    735|               1|\n",
      "+-------+----------+----+------------+---------+-------------+----------+--------------------+---------------+---------------+----+-----+-------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wine_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените <a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\">VectorAssembler</a> для создания вектора фич (задействуйте все свойства, кроме Customer_Segment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = VectorAssembler(\n",
    "    inputCols=wine_df.columns[:-1],\n",
    "    outputCol=\"features\")\n",
    "wine_df = feature.transform(wine_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cоздайте учителя KMeans со следующими параметрами K=3 Seed=1<br>\n",
    "Обучите модель и примените ее к тому же вектору.\n",
    "Документация по <a href=\"https://spark.apache.org/docs/latest/ml-clustering.html#k-means\">KMeans</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----+------------+---------+-------------+----------+--------------------+---------------+---------------+----+-----+-------+----------------+--------------------+----------+\n",
      "|Alcohol|Malic_Acid| Ash|Ash_Alcanity|Magnesium|Total_Phenols|Flavanoids|Nonflavanoid_Phenols|Proanthocyanins|Color_Intensity| Hue|OD280|Proline|Customer_Segment|            features|prediction|\n",
      "+-------+----------+----+------------+---------+-------------+----------+--------------------+---------------+---------------+----+-----+-------+----------------+--------------------+----------+\n",
      "|  14.23|      1.71|2.43|        15.6|      127|          2.8|      3.06|                0.28|           2.29|           5.64|1.04| 3.92|   1065|               1|[14.23,1.71,2.43,...|         2|\n",
      "|   13.2|      1.78|2.14|        11.2|      100|         2.65|      2.76|                0.26|           1.28|           4.38|1.05|  3.4|   1050|               1|[13.2,1.78,2.14,1...|         2|\n",
      "|  13.16|      2.36|2.67|        18.6|      101|          2.8|      3.24|                 0.3|           2.81|           5.68|1.03| 3.17|   1185|               1|[13.16,2.36,2.67,...|         1|\n",
      "|  14.37|      1.95| 2.5|        16.8|      113|         3.85|      3.49|                0.24|           2.18|            7.8|0.86| 3.45|   1480|               1|[14.37,1.95,2.5,1...|         1|\n",
      "|  13.24|      2.59|2.87|        21.0|      118|          2.8|      2.69|                0.39|           1.82|           4.32|1.04| 2.93|    735|               1|[13.24,2.59,2.87,...|         2|\n",
      "|   14.2|      1.76|2.45|        15.2|      112|         3.27|      3.39|                0.34|           1.97|           6.75|1.05| 2.85|   1450|               1|[14.2,1.76,2.45,1...|         1|\n",
      "|  14.39|      1.87|2.45|        14.6|       96|          2.5|      2.52|                 0.3|           1.98|           5.25|1.02| 3.58|   1290|               1|[14.39,1.87,2.45,...|         1|\n",
      "|  14.06|      2.15|2.61|        17.6|      121|          2.6|      2.51|                0.31|           1.25|           5.05|1.06| 3.58|   1295|               1|[14.06,2.15,2.61,...|         1|\n",
      "|  14.83|      1.64|2.17|        14.0|       97|          2.8|      2.98|                0.29|           1.98|            5.2|1.08| 2.85|   1045|               1|[14.83,1.64,2.17,...|         2|\n",
      "|  13.86|      1.35|2.27|        16.0|       98|         2.98|      3.15|                0.22|           1.85|           7.22|1.01| 3.55|   1045|               1|[13.86,1.35,2.27,...|         2|\n",
      "|   14.1|      2.16| 2.3|        18.0|      105|         2.95|      3.32|                0.22|           2.38|           5.75|1.25| 3.17|   1510|               1|[14.1,2.16,2.3,18...|         1|\n",
      "|  14.12|      1.48|2.32|        16.8|       95|          2.2|      2.43|                0.26|           1.57|            5.0|1.17| 2.82|   1280|               1|[14.12,1.48,2.32,...|         1|\n",
      "|  13.75|      1.73|2.41|        16.0|       89|          2.6|      2.76|                0.29|           1.81|            5.6|1.15|  2.9|   1320|               1|[13.75,1.73,2.41,...|         1|\n",
      "|  14.75|      1.73|2.39|        11.4|       91|          3.1|      3.69|                0.43|           2.81|            5.4|1.25| 2.73|   1150|               1|[14.75,1.73,2.39,...|         1|\n",
      "|  14.38|      1.87|2.38|        12.0|      102|          3.3|      3.64|                0.29|           2.96|            7.5| 1.2|  3.0|   1547|               1|[14.38,1.87,2.38,...|         1|\n",
      "|  13.63|      1.81| 2.7|        17.2|      112|         2.85|      2.91|                 0.3|           1.46|            7.3|1.28| 2.88|   1310|               1|[13.63,1.81,2.7,1...|         1|\n",
      "|   14.3|      1.92|2.72|        20.0|      120|          2.8|      3.14|                0.33|           1.97|            6.2|1.07| 2.65|   1280|               1|[14.3,1.92,2.72,2...|         1|\n",
      "|  13.83|      1.57|2.62|        20.0|      115|         2.95|       3.4|                 0.4|           1.72|            6.6|1.13| 2.57|   1130|               1|[13.83,1.57,2.62,...|         1|\n",
      "|  14.19|      1.59|2.48|        16.5|      108|          3.3|      3.93|                0.32|           1.86|            8.7|1.23| 2.82|   1680|               1|[14.19,1.59,2.48,...|         1|\n",
      "|  13.64|       3.1|2.56|        15.2|      116|          2.7|      3.03|                0.17|           1.66|            5.1|0.96| 3.36|    845|               1|[13.64,3.1,2.56,1...|         2|\n",
      "+-------+----------+----+------------+---------+-------------+----------+--------------------+---------------+---------------+----+-----+-------+----------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans().setK(3).setSeed(1)\n",
    "kmmodel = kmeans.fit(wine_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите силуэт с евклидовым расстоянием в квадрате для данных по вину(округлите до четвертого знака).\n",
    "<br><a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.ClusteringEvaluator\">ClusteringEvaluator</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7209450863531623"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = ClusteringEvaluator(predictionCol = \"prediction\")\n",
    "evaluator.evaluate(kmmodel.transform(wine_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №3 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузити датасет из файла <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week5/SparkML/spark-tasks/iris.parquet\">iris.parquet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = spark.read.parquet(\"./iris.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составьте из наших признаков вектор применив <a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\">VectorAssembler</a> как колонку features.\n",
    "<br> Задействуйте все признаки, кроме species, так как он является целевым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = VectorAssembler(\n",
    "inputCols=iris_df.columns[:-1],\n",
    "outputCol=\"features\")\n",
    "iris_df = features.transform(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте <a href=\"https://spark.apache.org/docs/latest/ml-features.html#stringindexer\">StringIndexer</a> и сделайте новый признак с именем type из целевого признака species который является категориальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = StringIndexer(inputCol=\"species\", outputCol=\"type\").fit(iris_df).transform(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+-----------------+----+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|         features|type|\n",
      "+------------+-----------+------------+-----------+-------+-----------------+----+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|[5.1,3.5,1.4,0.2]| 0.0|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|[4.9,3.0,1.4,0.2]| 0.0|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|[4.7,3.2,1.3,0.2]| 0.0|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|[4.6,3.1,1.5,0.2]| 0.0|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|[5.0,3.6,1.4,0.2]| 0.0|\n",
      "+------------+-----------+------------+-----------+-------+-----------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем выборки на обучение и тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = iris_df.randomSplit([0.8, 0.2],seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте и обучите <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier\">DecisionTreeClassifier</a> на датасете для обучения.\n",
    "Полученную модель используйте над тестовым датасетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"type\")\n",
    "dtcModel = dtc.fit(training_data)\n",
    "pred = dtcModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator\">MulticlassClassificationEvaluator</a> (помните что целевая фича это - type) для оценки качества модели по метрике accuracy.<br>Какая точность полученной модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MulticlassClassificationEvaluator(labelCol=\"type\", metricName=\"accuracy\").evaluate(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №4 Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте и обучите <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\">RandomForestClassifier</a> из 10 деревьев на датасете для обучения.\n",
    "Полученную модель примените к тестовому датасету.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "dtc = RandomForestClassifier(featuresCol=\"features\", labelCol=\"type\")\n",
    "dtcModel = dtc.fit(training_data)\n",
    "pred = dtcModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator\">MulticlassClassificationEvaluator</a> (помните что целевая фича это - type) для оценки качества модели по метрике accuracy.<br>Какая точность полученной модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MulticlassClassificationEvaluator(labelCol=\"type\", metricName=\"accuracy\").evaluate(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №5 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Займемся оптимизацией гиперпараметров для модели.\n",
    "Примените <a href='https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split'>TrainValidationSplit</a> для оптимизации гиперпараметров используя подготовленный вами выше датасет <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week5/SparkML/spark-tasks/iris.parquet\">iris.parquet</a> на модели <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\">RandomForestClassifier</a> совместно с <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator\">MulticlassClassificationEvaluator</a>.\n",
    "<br>Ваша цель определить оптимальные значения параметров из следующих диапазонов:\n",
    "<br>impurity = [\"entropy\", \"gini\"]\n",
    "<br>maxDepth = [2, 3, 4, 5]\n",
    "<br>numTrees = [3, 6, 9, 12, 15, 18, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = iris_df.withColumnRenamed(\"type\", \"label\")\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "model = TrainValidationSplit(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=ParamGridBuilder()\\\n",
    "        .addGrid(rf.impurity, [\"entropy\", \"gini\"])\\\n",
    "        .addGrid(rf.maxDepth, [2,3,4,5])\\\n",
    "        .addGrid(rf.numTrees, [3,6,9,12,15,18,21])\n",
    "        .build(),\n",
    "    evaluator = MulticlassClassificationEvaluator()\n",
    ").fit(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Trees: 9\n",
      "Max Depth: 3\n",
      "Impurity: entropy\n"
     ]
    }
   ],
   "source": [
    "print('Num Trees: {}'.format(model.bestModel._java_obj.getNumTrees()))\n",
    "print('Max Depth: {}'.format(model.bestModel._java_obj.getMaxDepth()))\n",
    "print('Impurity: {}'.format(model.bestModel._java_obj.getImpurity()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
