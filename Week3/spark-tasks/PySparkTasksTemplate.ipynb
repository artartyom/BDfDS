{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   @@@@@@@     @      @    @  @   #\n",
    "#   @  @  @    @ @      @  @       #\n",
    "#      @  @   @   @      @@    @   #\n",
    "#      @     @@@@@@@    @  @   @   #\n",
    "#      @    @       @  @    @  @   #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, в этой практике мы с вами применим наши знания по PySpark и постараемся изучить что-то новое в процессе выполнения.\n",
    "<br>В занятии используется датасет собранный на основе данных <a href=\"https://www.kaggle.com/chicago/chicago-taxi-rides-2016\">Chicago Taxi Rides 2016</a>\n",
    "<br>Полная <a href=\"https://spark.apache.org/docs/latest/api/python/index.html\">документация PySpark</a>.\n",
    "<br>Схема данны:\n",
    "<br>|-- taxi_id = идентификатор таксиста\n",
    "<br>|-- trip_start_timestamp = время начала поездки\n",
    "<br>|-- trip_end_timestamp = время окончания поездки\n",
    "<br>|-- trip_seconds = время длительности поездки в секундах\n",
    "<br>|-- trip_miles = мили проиденные во время поездки\n",
    "<br>|-- fare = транспортные расходы\n",
    "<br>|-- tips = назначенные чаевые\n",
    "<br>|-- trip_total = общая стоимость поездки\n",
    "<br>|-- payment_type = тип оплаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('PySparkTasks').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.session.timeZone\", \"GMT+3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.206:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkTasks</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd001a36fa0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week3/spark-tasks/taxi_data.parquet\">taxi_data.parquet</a> и загрузите используя <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame\">SparkAPI</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"./taxi_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№1 Посчитайте количество загруженных строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2540712"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------+------------+----------+-----+-----+----------+------------+\n",
      "|taxi_id|trip_start_timestamp| trip_end_timestamp|trip_seconds|trip_miles| fare| tips|trip_total|payment_type|\n",
      "+-------+--------------------+-------------------+------------+----------+-----+-----+----------+------------+\n",
      "|   5240| 2016-12-15 23:45:00|2016-12-16 00:00:00|         900|       2.5|10.75| 2.45|      14.7| Credit Card|\n",
      "|   1215| 2016-12-12 07:15:00|2016-12-12 07:15:00|         240|       0.4|  5.0|  3.0|       9.5| Credit Card|\n",
      "|   3673| 2016-12-16 16:30:00|2016-12-16 17:00:00|        2400|      10.7| 31.0|  0.0|      31.0|        Cash|\n",
      "|   5400| 2016-12-16 08:45:00|2016-12-16 09:00:00|         300|       0.0| 5.25|  2.0|      7.25| Credit Card|\n",
      "|   1257| 2016-12-03 18:45:00|2016-12-03 18:45:00|         360|       0.3|  5.0|  0.0|       5.0|        Cash|\n",
      "|   4666| 2016-12-30 18:00:00|2016-12-30 18:45:00|        2400|      18.2|46.75|10.15|      61.4| Credit Card|\n",
      "|   5998| 2016-12-16 07:15:00|2016-12-16 07:45:00|        1800|      18.4| 45.0|11.25|     56.25| Credit Card|\n",
      "|   2538| 2016-12-31 17:15:00|2016-12-31 17:15:00|         540|       0.0| 6.75|  0.0|      7.75|        Cash|\n",
      "|   6594| 2016-12-17 12:00:00|2016-12-17 12:00:00|         153|      0.47|  4.5|  1.0|       6.0| Credit Card|\n",
      "|   7864| 2016-12-03 19:45:00|2016-12-03 20:00:00|         780|       2.4| 10.5|  2.0|      12.5| Credit Card|\n",
      "|    400| 2016-12-06 15:30:00|2016-12-06 16:30:00|        3120|      10.9|31.75| 7.93|     40.18| Credit Card|\n",
      "|   6482| 2016-12-09 09:30:00|2016-12-09 09:30:00|         660|      1.32| 7.75|  2.0|     10.25| Credit Card|\n",
      "|   5856| 2016-12-29 18:45:00|2016-12-29 19:00:00|         300|       0.0| 5.25|  0.0|      6.75|        Cash|\n",
      "|   7211| 2016-12-12 22:30:00|2016-12-12 23:00:00|        1320|      14.1| 36.0|  0.0|      41.0|        Cash|\n",
      "|   1094| 2016-12-10 21:00:00|2016-12-10 21:00:00|         540|       1.4| 6.75|  4.0|     10.75| Credit Card|\n",
      "|   6591| 2016-12-22 22:45:00|2016-12-22 23:00:00|         480|       1.7| 7.75|  0.0|      7.75|        Cash|\n",
      "|   6514| 2016-12-30 11:00:00|2016-12-30 11:00:00|         480|       1.5|  7.5|  0.0|       7.5|        Cash|\n",
      "|   8267| 2016-12-17 04:15:00|2016-12-17 04:15:00|         360|       1.9| 7.75|  4.0|     13.25| Credit Card|\n",
      "|   8002| 2016-12-19 12:15:00|2016-12-19 12:15:00|         300|       0.9|  6.0|  2.0|       8.5| Credit Card|\n",
      "|   2718| 2016-12-19 10:15:00|2016-12-19 10:45:00|        1920|       5.6|18.75|  0.0|     18.75|        Cash|\n",
      "+-------+--------------------+-------------------+------------+----------+-----+-----+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим схему данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- taxi_id: integer (nullable = true)\n",
      " |-- trip_start_timestamp: timestamp (nullable = true)\n",
      " |-- trip_end_timestamp: timestamp (nullable = true)\n",
      " |-- trip_seconds: integer (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- trip_total: double (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№2 Чему равна корреляция и ковариация между длиной маршрута и ценой за поездку? Ответ округлите до 5 знаков после запятой.\n",
    "<br>Подробнее <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.corr\">corr</a> & <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.cov\">cov</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44816152497587586"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(\"trip_miles\", \"trip_total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№3 Найдите количество, среднее, cреднеквадратическое отклонение, минимум и максимум для длины маршрута и цены за поездку? Ответ округлите до 1 знака после запятой. Подробнее <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.describe\">describe</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|        trip_total|        trip_miles|\n",
      "+-------+------------------+------------------+\n",
      "|  count|           2540672|           2540677|\n",
      "|   mean|15.913560215564042|3.0005873828090266|\n",
      "| stddev|30.546699217618237|  5.25716922943536|\n",
      "|    min|               0.0|               0.0|\n",
      "|    max|           9276.69|             900.0|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe([\"trip_total\", \"trip_miles\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№4 Найдите самый НЕ популярный вид оплаты.\n",
    "<br>Подробнее <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.groupBy\">groupBy</a> <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.orderBy\">orderBy</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|payment_type|  count|\n",
      "+------------+-------+\n",
      "|    Way2ride|      3|\n",
      "|       Pcard|    878|\n",
      "|      Prcard|    968|\n",
      "|     Dispute|   1842|\n",
      "|     Unknown|   5180|\n",
      "|   No Charge|  12843|\n",
      "| Credit Card|1108843|\n",
      "|        Cash|1410155|\n",
      "+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"payment_type\").count().orderBy(\"count\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№5 Найдите идентификатор таксиста выполнившего наибольшее число заказов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|taxi_id|count|\n",
      "+-------+-----+\n",
      "|    316| 2225|\n",
      "|   6591| 2083|\n",
      "|   5071| 2080|\n",
      "|   8740| 2067|\n",
      "|   6008| 2033|\n",
      "|   8629| 2024|\n",
      "|   1462| 2007|\n",
      "|    375| 1986|\n",
      "|   8751| 1938|\n",
      "|   5357| 1930|\n",
      "|   8264| 1909|\n",
      "|   1168| 1809|\n",
      "|   1946| 1803|\n",
      "|    336| 1799|\n",
      "|   1521| 1799|\n",
      "|   3253| 1764|\n",
      "|   8561| 1760|\n",
      "|   8344| 1743|\n",
      "|   8496| 1742|\n",
      "|   6482| 1740|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"taxi_id\").count().orderBy(\"count\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№6 Чему равна средняя цена среди поездок, оплаченных наличными? Ответ округлите до 5 знака.\n",
    "<br> Подробней <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.where\">where</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+------------------+------------------+--------------------+------------------+\n",
      "|     avg(taxi_id)|avg(trip_seconds)|   avg(trip_miles)|         avg(fare)|           avg(tips)|   avg(trip_total)|\n",
      "+-----------------+-----------------+------------------+------------------+--------------------+------------------+\n",
      "|4360.783044157716|712.4986067049796|2.2804813271493494|11.194248598877067|0.003325194540318936|12.035261470840307|\n",
      "+-----------------+-----------------+------------------+------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.payment_type == \"Cash\").groupBy().avg().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№7 Сколько таксистов проехало больше 1000 миль за все время выполнения заказов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2860"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.groupBy(\"taxi_id\").sum(\"trip_miles\").withColumnRenamed(\"sum(trip_miles)\", \"totalSum\")\n",
    "df2.filter(df2.totalSum > 1000).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№8 Сколько миль проехал пассажир в самой долгой поездке? (Ответ округлите до целого)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------+------------+----------+----+----+----------+------------+\n",
      "|taxi_id|trip_start_timestamp| trip_end_timestamp|trip_seconds|trip_miles|fare|tips|trip_total|payment_type|\n",
      "+-------+--------------------+-------------------+------------+----------+----+----+----------+------------+\n",
      "|   5667| 2016-11-04 21:30:00|2016-11-05 21:30:00|       86399|       0.0|3.25| 0.0|      4.75|        Cash|\n",
      "|   4161| 2016-11-14 16:00:00|2016-11-15 16:00:00|       86399|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|   1954| 2016-11-03 00:15:00|2016-11-04 00:15:00|       86399|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|   4219| 2016-11-08 16:00:00|2016-11-09 16:00:00|       86392|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|   4551| 2016-11-03 16:15:00|2016-11-04 16:15:00|       86389|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|   5327| 2016-11-01 14:00:00|2016-11-02 14:00:00|       86389|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|   8129| 2016-11-15 06:00:00|2016-11-16 06:00:00|       86388|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|   2845| 2016-11-10 07:45:00|2016-11-11 07:45:00|       86387|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|   2845| 2016-11-10 07:00:00|2016-11-11 07:00:00|       86386|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|    293| 2016-11-10 17:45:00|2016-11-11 17:45:00|       86386|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|   2845| 2016-11-06 22:15:00|2016-11-07 22:15:00|       86385|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|   6117| 2016-11-12 17:15:00|2016-11-13 17:15:00|       86385|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|   1887| 2016-11-04 10:00:00|2016-11-05 10:00:00|       86385|       0.0|3.25| 0.0|      4.25|        Cash|\n",
      "|   4219| 2016-11-09 22:45:00|2016-11-10 22:45:00|       86384|      0.06|3.25| 0.0|      3.25|        Cash|\n",
      "|    293| 2016-11-11 17:00:00|2016-11-12 17:00:00|       86384|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|    293| 2016-11-15 17:00:00|2016-11-16 17:00:00|       86379|      0.07|3.25| 0.0|      3.25|        Cash|\n",
      "|   7321| 2016-11-06 18:30:00|2016-11-07 18:30:00|       86376|      0.09|3.25| 0.0|      3.25|        Cash|\n",
      "|   5327| 2016-11-07 13:30:00|2016-11-08 13:15:00|       86375|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|   5802| 2016-11-09 12:15:00|2016-11-10 12:15:00|       86370|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "|   8056| 2016-11-01 05:00:00|2016-11-02 05:00:00|       86368|       0.0|3.25| 0.0|      3.25|        Cash|\n",
      "+-------+--------------------+-------------------+------------+----------+----+----+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"trip_seconds\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№9 Каков средний заработок всех таксистов? Ответ округлите до 5-ого знака.\n",
    "<br>Отсеките неизвестные машины (не определенный taxi_id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|avg(sum(trip_total))|\n",
      "+--------------------+\n",
      "|   8218.856265256312|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.taxi_id.isNotNull()).groupBy(\"taxi_id\").sum(\"trip_total\").agg({\"sum(trip_total)\" : \"avg\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№10 Сколько поездок начиналось в самый загруженный час?\n",
    "<br>Используйте функцию <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.hour\">hour</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|hourCol| count|\n",
      "+-------+------+\n",
      "|     18|181127|\n",
      "|     19|173779|\n",
      "|     17|169886|\n",
      "|     16|156519|\n",
      "|     20|146602|\n",
      "|     15|144400|\n",
      "|     14|141347|\n",
      "|     13|140899|\n",
      "|     12|136580|\n",
      "|     21|126776|\n",
      "|     11|121196|\n",
      "|      9|118125|\n",
      "|     22|116996|\n",
      "|     10|114401|\n",
      "|      8| 97980|\n",
      "|     23| 97774|\n",
      "|      0| 75971|\n",
      "|      1| 62165|\n",
      "|      7| 58212|\n",
      "|      2| 49114|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"hourCol\", hour(df.trip_start_timestamp)).groupBy(\"hourCol\").count().orderBy(\"count\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№11 Сколько поездок началось во второй четверти дня?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| count|\n",
      "+------+\n",
      "|538737|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.\\\n",
    "withColumn(\"hourCol\", hour(df.trip_start_timestamp)).\\\n",
    "filter(\"hourCol >= 6 and hourCol < 12\").\\\n",
    "groupBy().count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№12 Найдите топ три даты, в которые было суммарно больше всего чаевых? (Чаевые выдаются после совершения поездки)\n",
    "<br> Ожидаемый формат дат YYYY-MM-DD\n",
    "<br>Вам может понадобится конвертация типов <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column.cast\">cast</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|      date|         sum(tips)|\n",
      "+----------+------------------+\n",
      "|2016-11-03|110102.37000000013|\n",
      "|2016-11-09|106187.87999999986|\n",
      "|2016-11-16| 99993.77000000038|\n",
      "|2016-12-01| 97954.88000000014|\n",
      "|2016-11-10| 97263.90000000063|\n",
      "|2016-11-04| 96244.83000000005|\n",
      "|2016-11-17| 95188.28000000052|\n",
      "|2016-12-08| 94128.17000000039|\n",
      "|2016-11-08| 90394.94000000024|\n",
      "|2016-12-15| 89820.06000000052|\n",
      "|2016-11-18|  89685.4800000007|\n",
      "|2016-11-02| 89175.40000000023|\n",
      "|2016-11-30| 88441.87000000021|\n",
      "|2016-11-07| 87743.85000000036|\n",
      "|2016-11-15| 85591.05999999978|\n",
      "|2016-12-14| 85584.15000000011|\n",
      "|2016-11-11| 85330.95000000014|\n",
      "|2016-12-09| 84563.74999999993|\n",
      "|2016-12-07| 83296.74000000034|\n",
      "|2016-12-16| 81553.82000000037|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"date\", df.trip_end_timestamp.cast(\"Date\")).groupBy(\"date\").sum(\"tips\").orderBy(\"sum(tips)\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№13 Сколько было заказов в дату с наибольшим спросом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|count|\n",
      "+----------+-----+\n",
      "|2016-11-03|61259|\n",
      "|2016-12-16|59137|\n",
      "|2016-12-09|58583|\n",
      "|2016-12-15|57084|\n",
      "|2016-11-04|56800|\n",
      "|2016-12-08|56786|\n",
      "|2016-11-18|56382|\n",
      "|2016-12-02|55914|\n",
      "|2016-12-01|55298|\n",
      "|2016-12-14|53096|\n",
      "|2016-11-02|51677|\n",
      "|2016-11-05|51341|\n",
      "|2016-11-10|50970|\n",
      "|2016-11-30|50904|\n",
      "|2016-11-09|50894|\n",
      "|2016-11-17|50849|\n",
      "|2016-11-11|50148|\n",
      "|2016-11-16|49653|\n",
      "|2016-12-07|49653|\n",
      "|2016-11-08|48566|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"date\", df.trip_start_timestamp.cast(\"Date\")).groupBy(\"date\").count().orderBy(\"count\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгрузите данные о марках машин из датасета <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week3/spark-tasks/taxi_cars_data.parquet\">taxi_cars_data.parquet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car = spark.read.parquet(\"taxi_cars_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|taxi_id|          car_model|\n",
      "+-------+-------------------+\n",
      "|   1159|       Toyota Prius|\n",
      "|   7273|Ford Crown Victoria|\n",
      "|   2904|        Honda Civic|\n",
      "|   3210|        Ford Fusion|\n",
      "|   2088|       Toyota Camry|\n",
      "|   4821|Ford Crown Victoria|\n",
      "|   2069|    Hyundai Elantra|\n",
      "|   6240|       Toyota Camry|\n",
      "|    296|     Hyundai Sonata|\n",
      "|   2136|Ford Crown Victoria|\n",
      "|   1436|     Toyota Corolla|\n",
      "|   1090|     Toyota Corolla|\n",
      "|   7711|        Lincoln MKZ|\n",
      "|   1572|Ford Crown Victoria|\n",
      "|   3959|     Chevrolet Aveo|\n",
      "|   5645|  Chevrolet Lacetti|\n",
      "|   5149|            Audi A7|\n",
      "|   6366|     Hyundai Sonata|\n",
      "|    451|     Hyundai Accent|\n",
      "|   1669|           Kia Ceed|\n",
      "+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_car.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№14 Какая марка машины самая распрастранненая среди таксистов?\n",
    "<br>Подробнее <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.split\">split</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|  carModel|count|\n",
      "+----------+-----+\n",
      "|      Ford| 1484|\n",
      "|   Hyundai|  792|\n",
      "|    Toyota|  691|\n",
      "| Chevrolet|  473|\n",
      "|       Kia|  265|\n",
      "|      Audi|  250|\n",
      "|   Lincoln|  247|\n",
      "|     Honda|  246|\n",
      "|Volkswagen|  244|\n",
      "|    Nissan|  225|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_car.withColumn(\"carModel\", split(df_car.car_model, \" \")[0]).groupBy(\"carModel\").count().orderBy(\"count\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№15 Сколько раз и какая модель машин чаще всего встречается в поездках?\n",
    "<br>Подробнее <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.join\">join</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|          car_model| count|\n",
      "+-------------------+------+\n",
      "|Ford Crown Victoria|388682|\n",
      "|     Hyundai Accent|150764|\n",
      "|           Kia Ceed|143649|\n",
      "|     Hyundai Sonata|141570|\n",
      "|        Ford Mondeo|135466|\n",
      "|    Hyundai Elantra|134722|\n",
      "|        Honda Civic|133848|\n",
      "|            Audi A7|129168|\n",
      "|  Chevrolet Lacetti|128803|\n",
      "|     Toyota Corolla|125434|\n",
      "|        Lincoln MKZ|124616|\n",
      "|       Toyota Camry|123249|\n",
      "|    Volkswagen Golf|118449|\n",
      "|        Ford Taurus|116836|\n",
      "|        Ford Fusion|113828|\n",
      "|       Toyota Prius|113099|\n",
      "|     Chevrolet Aveo|109326|\n",
      "|      Nissan Altima|108038|\n",
      "+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df_car, \"taxi_id\").groupBy(\"car_model\").count().orderBy(\"count\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почувствуй силу сжатия! сохрани DataFrame в csv и сравни размеры файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код с coalesce(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь загрузите данные из csv и проверьте типы методом printSchema()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код с printSchema() для DataFrame из csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забудьте посетить SparkUI и изучить историю ваших задач."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
